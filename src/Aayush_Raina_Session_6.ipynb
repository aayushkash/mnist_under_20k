{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DROP_OUT = 0.05\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(DROP_OUT)\n",
        "        )  # output_size = 26, receptive_field = 3, output_channels = 16\n",
        "\n",
        "        # Convolution Block 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(DROP_OUT)\n",
        "        )  # output_size = 24, receptive_field = 5, output_channels = 32\n",
        "\n",
        "        # Transition Block 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 12, 1, padding=0, bias=False),\n",
        "        )  # output_size = 24, receptive_field = 5, output_channels = 12\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # output_size = 12, receptive_field = 6, output_channels = 14\n",
        "\n",
        "        # Convolution Block 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(12, 16, 3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(DROP_OUT)\n",
        "        )  # output_size = 10, receptive_field = 10, output_channels = 16\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(DROP_OUT)\n",
        "        )  # output_size = 8, receptive_field = 14, output_channels = 16\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(DROP_OUT)\n",
        "        )  # output_size = 6, receptive_field = 18, output_channels = 16\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(DROP_OUT)\n",
        "        )  # output_size = 6, receptive_field = 22, output_channels = 16\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        self.fc = nn.Linear(16 * 6 * 6, 10)  # 16 channels, 6x6 feature map\n",
        "\n",
        "        self.dropout = nn.Dropout(DROP_OUT)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = x.view(-1, 16 * 6 * 6)  # Flatten the tensor\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "1gyPRQm4e2Ai"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4cedde-0862-42e1-c38a-f5dfb32e9446"
      },
      "source": [
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "              ReLU-2           [-1, 16, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 16, 26, 26]              32\n",
            "           Dropout-4           [-1, 16, 26, 26]               0\n",
            "            Conv2d-5           [-1, 32, 24, 24]           4,608\n",
            "              ReLU-6           [-1, 32, 24, 24]               0\n",
            "       BatchNorm2d-7           [-1, 32, 24, 24]              64\n",
            "           Dropout-8           [-1, 32, 24, 24]               0\n",
            "            Conv2d-9           [-1, 12, 24, 24]             384\n",
            "        MaxPool2d-10           [-1, 12, 12, 12]               0\n",
            "           Conv2d-11           [-1, 16, 10, 10]           1,728\n",
            "             ReLU-12           [-1, 16, 10, 10]               0\n",
            "      BatchNorm2d-13           [-1, 16, 10, 10]              32\n",
            "          Dropout-14           [-1, 16, 10, 10]               0\n",
            "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
            "             ReLU-16             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 16, 8, 8]              32\n",
            "          Dropout-18             [-1, 16, 8, 8]               0\n",
            "           Conv2d-19             [-1, 16, 6, 6]           2,304\n",
            "             ReLU-20             [-1, 16, 6, 6]               0\n",
            "      BatchNorm2d-21             [-1, 16, 6, 6]              32\n",
            "          Dropout-22             [-1, 16, 6, 6]               0\n",
            "           Conv2d-23             [-1, 16, 6, 6]           2,304\n",
            "             ReLU-24             [-1, 16, 6, 6]               0\n",
            "      BatchNorm2d-25             [-1, 16, 6, 6]              32\n",
            "          Dropout-26             [-1, 16, 6, 6]               0\n",
            "           Linear-27                   [-1, 10]           5,770\n",
            "================================================================\n",
            "Total params: 19,770\n",
            "Trainable params: 19,770\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.07\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "def get_data_loaders(batch_size=64):\n",
        "\n",
        "    train_transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-5.0, 5.0), fill=(1,)),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load full datasets\n",
        "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=train_transform)\n",
        "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "    # Create indices for 25% of training data\n",
        "    # total_train = len(train_dataset)\n",
        "    # indices = np.random.permutation(total_train)\n",
        "    # train_size = int(0.25 * total_train)  # 25% of the data\n",
        "    # train_indices = indices[:train_size]\n",
        "\n",
        "    # Create subset of training data\n",
        "    # train_dataset = Subset(train_dataset, train_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # print(f\"Training with {train_size:,} samples (25% of original {total_train:,} samples)\")\n",
        "    print(f\"Training with {len(train_dataset)} samples\")\n",
        "\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "def setup_logger():\n",
        "    log_dir = Path('logs')\n",
        "    log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        filename=f'logs/training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log',\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(message)s'\n",
        "    )\n",
        "\n",
        "def get_device():\n",
        "    if torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        device_name = \"Apple Silicon (M1/M2)\"\n",
        "    elif torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        device_name = f\"CUDA ({torch.cuda.get_device_name(0)})\"\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        device_name = \"CPU\"\n",
        "    return device, device_name\n",
        "\n",
        "def train(epochs=20, batch_size=64, learning_rate=0.01, target_accuracy=99.4):\n",
        "    set_seed(42)  # Set seed for reproducibility\n",
        "    setup_logger()\n",
        "\n",
        "    # Device setup\n",
        "    device, device_name = get_device()\n",
        "    gpu_info = f\"Using device: {device} ({device_name})\"\n",
        "\n",
        "    if device.type == 'cuda':\n",
        "        gpu_info += f\"\\nMemory Usage:\"\n",
        "        gpu_info += f\"\\n  Allocated: {round(torch.cuda.memory_allocated(0)/1024**2,1)} MB\"\n",
        "        gpu_info += f\"\\n  Cached:    {round(torch.cuda.memory_reserved(0)/1024**2,1)} MB\"\n",
        "\n",
        "    print(gpu_info)\n",
        "    # logging.info(gpu_info)\n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    train_loader, test_loader = get_data_loaders(batch_size)\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            # Print batch progress\n",
        "            # if batch_idx % 100 == 0:\n",
        "            #     print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "            #           f'({100. * batch_idx / len(train_loader):.0f}%)]  Loss: {loss.item():.6f}')\n",
        "\n",
        "        train_accuracy = 100. * correct / total\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                val_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                _, predicted = output.max(1)\n",
        "                total += target.size(0)\n",
        "                correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        val_accuracy = 100. * correct / total\n",
        "        val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        # Update best accuracy\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_accuracy >= target_accuracy:\n",
        "            early_stop = True\n",
        "            print(f\"\\nReached target accuracy of {target_accuracy}% at epoch {epoch}\")\n",
        "            # logging.info(f\"Reached target accuracy of {target_accuracy}% at epoch {epoch}\")\n",
        "\n",
        "        # Log epoch results\n",
        "        log_message = (f'Epoch: {epoch} | '\n",
        "                      f'Train Loss: {train_loss:.3f} | '\n",
        "                      f'Train Acc: {train_accuracy:.2f}% | '\n",
        "                      f'Val Loss: {val_loss:.3f} | '\n",
        "                      f'Val Acc: {val_accuracy:.2f}% | '\n",
        "                      f'Best Val Acc: {best_accuracy:.2f}%')\n",
        "        # logging.info(log_message)\n",
        "        print(log_message)\n",
        "\n",
        "        # Log GPU memory only for CUDA devices\n",
        "        if device.type == 'cuda':\n",
        "            memory_info = (f\"GPU Memory: \"\n",
        "                         f\"Allocated: {round(torch.cuda.memory_allocated(0)/1024**2,1)} MB, \"\n",
        "                         f\"Cached: {round(torch.cuda.memory_reserved(0)/1024**2,1)} MB\")\n",
        "            # logging.info(memory_info)\n",
        "            print(memory_info)\n",
        "\n",
        "    return best_accuracy"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840fba14-08cd-472c-f75a-b7ba4db7b796"
      },
      "source": [
        "final_accuracy = train()\n",
        "print(f\"\\nTraining completed. Best validation accuracy: {final_accuracy:.2f}%\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda (CUDA (Tesla T4))\n",
            "Memory Usage:\n",
            "  Allocated: 17.7 MB\n",
            "  Cached:    120.0 MB\n",
            "Training with 60000 samples\n",
            "Epoch: 0 | Train Loss: 0.129 | Train Acc: 95.84% | Val Loss: 3.849 | Val Acc: 98.08% | Best Val Acc: 98.08%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 1 | Train Loss: 0.051 | Train Acc: 98.37% | Val Loss: 2.142 | Val Acc: 98.90% | Best Val Acc: 98.90%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 2 | Train Loss: 0.040 | Train Acc: 98.74% | Val Loss: 1.735 | Val Acc: 99.16% | Best Val Acc: 99.16%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 3 | Train Loss: 0.035 | Train Acc: 98.89% | Val Loss: 1.746 | Val Acc: 99.08% | Best Val Acc: 99.16%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 4 | Train Loss: 0.030 | Train Acc: 99.04% | Val Loss: 1.783 | Val Acc: 99.10% | Best Val Acc: 99.16%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 5 | Train Loss: 0.027 | Train Acc: 99.15% | Val Loss: 1.539 | Val Acc: 99.28% | Best Val Acc: 99.28%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 6 | Train Loss: 0.025 | Train Acc: 99.19% | Val Loss: 1.580 | Val Acc: 99.26% | Best Val Acc: 99.28%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 7 | Train Loss: 0.023 | Train Acc: 99.30% | Val Loss: 1.634 | Val Acc: 99.23% | Best Val Acc: 99.28%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 8 | Train Loss: 0.022 | Train Acc: 99.29% | Val Loss: 1.436 | Val Acc: 99.34% | Best Val Acc: 99.34%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 9 | Train Loss: 0.019 | Train Acc: 99.38% | Val Loss: 1.330 | Val Acc: 99.31% | Best Val Acc: 99.34%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 10 | Train Loss: 0.019 | Train Acc: 99.40% | Val Loss: 1.457 | Val Acc: 99.34% | Best Val Acc: 99.34%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 11 | Train Loss: 0.018 | Train Acc: 99.39% | Val Loss: 1.627 | Val Acc: 99.24% | Best Val Acc: 99.34%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 12 | Train Loss: 0.017 | Train Acc: 99.45% | Val Loss: 1.275 | Val Acc: 99.39% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 13 | Train Loss: 0.016 | Train Acc: 99.47% | Val Loss: 1.358 | Val Acc: 99.33% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 14 | Train Loss: 0.016 | Train Acc: 99.47% | Val Loss: 1.404 | Val Acc: 99.32% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 15 | Train Loss: 0.014 | Train Acc: 99.52% | Val Loss: 1.362 | Val Acc: 99.31% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 16 | Train Loss: 0.015 | Train Acc: 99.51% | Val Loss: 1.389 | Val Acc: 99.36% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 17 | Train Loss: 0.014 | Train Acc: 99.54% | Val Loss: 1.504 | Val Acc: 99.29% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 18 | Train Loss: 0.014 | Train Acc: 99.53% | Val Loss: 1.428 | Val Acc: 99.38% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "Epoch: 19 | Train Loss: 0.012 | Train Acc: 99.58% | Val Loss: 1.378 | Val Acc: 99.37% | Best Val Acc: 99.39%\n",
            "GPU Memory: Allocated: 18.0 MB, Cached: 120.0 MB\n",
            "\n",
            "Training completed. Best validation accuracy: 99.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}